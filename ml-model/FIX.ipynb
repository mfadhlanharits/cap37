{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6464de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78d38297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37d5d605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#Data types of variable\n",
    "print(type(x_train))\n",
    "print(type(y_train))\n",
    "print(type(x_test))\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4ebd880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28)\n",
      "y_train shape: (60000,)\n",
      "x_test shape: (10000, 28, 28)\n",
      "y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "#Shape of the arrays\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25dc7133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
       "          0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
       "         10,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
       "         72,  15],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
       "        172,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
       "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
       "        229,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
       "        173,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
       "        202,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
       "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
       "        209,  52],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
       "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
       "        167,  56],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "         92,   0],\n",
       "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
       "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
       "         77,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
       "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
       "        159,   0],\n",
       "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
       "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
       "        215,   0],\n",
       "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
       "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
       "        246,   0],\n",
       "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
       "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
       "        225,   0],\n",
       "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
       "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
       "        229,  29],\n",
       "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
       "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
       "        230,  67],\n",
       "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
       "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
       "        206, 115],\n",
       "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
       "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
       "        210,  92],\n",
       "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
       "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
       "        170,   0],\n",
       "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
       "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The first image as an array\n",
    "index = 0\n",
    "x_train[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcac10b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Show the image as a picture\n",
    "img = plt.imshow(x_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e0208a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image label is: 9\n"
     ]
    }
   ],
   "source": [
    "#Image label\n",
    "print('The image label is:', y_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f8310d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the labels into a set of 10 numbers to input the neural network\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "753ad728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Print new labels\n",
    "print(y_train_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af8c6177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The one hot label is: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "#Print the new label of the image/picture above\n",
    "print('The one hot label is:', y_train_one_hot[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75f89587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the pixels to be values between o and 1\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19bca782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
       "        0.05098039, 0.28627451, 0.        , 0.        , 0.00392157,\n",
       "        0.01568627, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00392157, 0.00392157, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.        , 0.14117647,\n",
       "        0.53333333, 0.49803922, 0.24313725, 0.21176471, 0.        ,\n",
       "        0.        , 0.        , 0.00392157, 0.01176471, 0.01568627,\n",
       "        0.        , 0.        , 0.01176471],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
       "        0.8       , 0.69019608, 0.5254902 , 0.56470588, 0.48235294,\n",
       "        0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04705882, 0.03921569, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.60784314,\n",
       "        0.9254902 , 0.81176471, 0.69803922, 0.41960784, 0.61176471,\n",
       "        0.63137255, 0.42745098, 0.25098039, 0.09019608, 0.30196078,\n",
       "        0.50980392, 0.28235294, 0.05882353],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00392157, 0.        , 0.27058824, 0.81176471,\n",
       "        0.8745098 , 0.85490196, 0.84705882, 0.84705882, 0.63921569,\n",
       "        0.49803922, 0.4745098 , 0.47843137, 0.57254902, 0.55294118,\n",
       "        0.34509804, 0.6745098 , 0.25882353],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.00392157, 0.00392157, 0.        , 0.78431373, 0.90980392,\n",
       "        0.90980392, 0.91372549, 0.89803922, 0.8745098 , 0.8745098 ,\n",
       "        0.84313725, 0.83529412, 0.64313725, 0.49803922, 0.48235294,\n",
       "        0.76862745, 0.89803922, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.71764706, 0.88235294,\n",
       "        0.84705882, 0.8745098 , 0.89411765, 0.92156863, 0.89019608,\n",
       "        0.87843137, 0.87058824, 0.87843137, 0.86666667, 0.8745098 ,\n",
       "        0.96078431, 0.67843137, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.75686275, 0.89411765,\n",
       "        0.85490196, 0.83529412, 0.77647059, 0.70588235, 0.83137255,\n",
       "        0.82352941, 0.82745098, 0.83529412, 0.8745098 , 0.8627451 ,\n",
       "        0.95294118, 0.79215686, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.01176471, 0.        , 0.04705882, 0.85882353, 0.8627451 ,\n",
       "        0.83137255, 0.85490196, 0.75294118, 0.6627451 , 0.89019608,\n",
       "        0.81568627, 0.85490196, 0.87843137, 0.83137255, 0.88627451,\n",
       "        0.77254902, 0.81960784, 0.20392157],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02352941, 0.        , 0.38823529, 0.95686275, 0.87058824,\n",
       "        0.8627451 , 0.85490196, 0.79607843, 0.77647059, 0.86666667,\n",
       "        0.84313725, 0.83529412, 0.87058824, 0.8627451 , 0.96078431,\n",
       "        0.46666667, 0.65490196, 0.21960784],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01568627,\n",
       "        0.        , 0.        , 0.21568627, 0.9254902 , 0.89411765,\n",
       "        0.90196078, 0.89411765, 0.94117647, 0.90980392, 0.83529412,\n",
       "        0.85490196, 0.8745098 , 0.91764706, 0.85098039, 0.85098039,\n",
       "        0.81960784, 0.36078431, 0.        ],\n",
       "       [0.        , 0.        , 0.00392157, 0.01568627, 0.02352941,\n",
       "        0.02745098, 0.00784314, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.92941176, 0.88627451, 0.85098039,\n",
       "        0.8745098 , 0.87058824, 0.85882353, 0.87058824, 0.86666667,\n",
       "        0.84705882, 0.8745098 , 0.89803922, 0.84313725, 0.85490196,\n",
       "        1.        , 0.30196078, 0.        ],\n",
       "       [0.        , 0.01176471, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.24313725,\n",
       "        0.56862745, 0.8       , 0.89411765, 0.81176471, 0.83529412,\n",
       "        0.86666667, 0.85490196, 0.81568627, 0.82745098, 0.85490196,\n",
       "        0.87843137, 0.8745098 , 0.85882353, 0.84313725, 0.87843137,\n",
       "        0.95686275, 0.62352941, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.07058824,\n",
       "        0.17254902, 0.32156863, 0.41960784, 0.74117647, 0.89411765,\n",
       "        0.8627451 , 0.87058824, 0.85098039, 0.88627451, 0.78431373,\n",
       "        0.80392157, 0.82745098, 0.90196078, 0.87843137, 0.91764706,\n",
       "        0.69019608, 0.7372549 , 0.98039216, 0.97254902, 0.91372549,\n",
       "        0.93333333, 0.84313725, 0.        ],\n",
       "       [0.        , 0.22352941, 0.73333333, 0.81568627, 0.87843137,\n",
       "        0.86666667, 0.87843137, 0.81568627, 0.8       , 0.83921569,\n",
       "        0.81568627, 0.81960784, 0.78431373, 0.62352941, 0.96078431,\n",
       "        0.75686275, 0.80784314, 0.8745098 , 1.        , 1.        ,\n",
       "        0.86666667, 0.91764706, 0.86666667, 0.82745098, 0.8627451 ,\n",
       "        0.90980392, 0.96470588, 0.        ],\n",
       "       [0.01176471, 0.79215686, 0.89411765, 0.87843137, 0.86666667,\n",
       "        0.82745098, 0.82745098, 0.83921569, 0.80392157, 0.80392157,\n",
       "        0.80392157, 0.8627451 , 0.94117647, 0.31372549, 0.58823529,\n",
       "        1.        , 0.89803922, 0.86666667, 0.7372549 , 0.60392157,\n",
       "        0.74901961, 0.82352941, 0.8       , 0.81960784, 0.87058824,\n",
       "        0.89411765, 0.88235294, 0.        ],\n",
       "       [0.38431373, 0.91372549, 0.77647059, 0.82352941, 0.87058824,\n",
       "        0.89803922, 0.89803922, 0.91764706, 0.97647059, 0.8627451 ,\n",
       "        0.76078431, 0.84313725, 0.85098039, 0.94509804, 0.25490196,\n",
       "        0.28627451, 0.41568627, 0.45882353, 0.65882353, 0.85882353,\n",
       "        0.86666667, 0.84313725, 0.85098039, 0.8745098 , 0.8745098 ,\n",
       "        0.87843137, 0.89803922, 0.11372549],\n",
       "       [0.29411765, 0.8       , 0.83137255, 0.8       , 0.75686275,\n",
       "        0.80392157, 0.82745098, 0.88235294, 0.84705882, 0.7254902 ,\n",
       "        0.77254902, 0.80784314, 0.77647059, 0.83529412, 0.94117647,\n",
       "        0.76470588, 0.89019608, 0.96078431, 0.9372549 , 0.8745098 ,\n",
       "        0.85490196, 0.83137255, 0.81960784, 0.87058824, 0.8627451 ,\n",
       "        0.86666667, 0.90196078, 0.2627451 ],\n",
       "       [0.18823529, 0.79607843, 0.71764706, 0.76078431, 0.83529412,\n",
       "        0.77254902, 0.7254902 , 0.74509804, 0.76078431, 0.75294118,\n",
       "        0.79215686, 0.83921569, 0.85882353, 0.86666667, 0.8627451 ,\n",
       "        0.9254902 , 0.88235294, 0.84705882, 0.78039216, 0.80784314,\n",
       "        0.72941176, 0.70980392, 0.69411765, 0.6745098 , 0.70980392,\n",
       "        0.80392157, 0.80784314, 0.45098039],\n",
       "       [0.        , 0.47843137, 0.85882353, 0.75686275, 0.70196078,\n",
       "        0.67058824, 0.71764706, 0.76862745, 0.8       , 0.82352941,\n",
       "        0.83529412, 0.81176471, 0.82745098, 0.82352941, 0.78431373,\n",
       "        0.76862745, 0.76078431, 0.74901961, 0.76470588, 0.74901961,\n",
       "        0.77647059, 0.75294118, 0.69019608, 0.61176471, 0.65490196,\n",
       "        0.69411765, 0.82352941, 0.36078431],\n",
       "       [0.        , 0.        , 0.29019608, 0.74117647, 0.83137255,\n",
       "        0.74901961, 0.68627451, 0.6745098 , 0.68627451, 0.70980392,\n",
       "        0.7254902 , 0.7372549 , 0.74117647, 0.7372549 , 0.75686275,\n",
       "        0.77647059, 0.8       , 0.81960784, 0.82352941, 0.82352941,\n",
       "        0.82745098, 0.7372549 , 0.7372549 , 0.76078431, 0.75294118,\n",
       "        0.84705882, 0.66666667, 0.        ],\n",
       "       [0.00784314, 0.        , 0.        , 0.        , 0.25882353,\n",
       "        0.78431373, 0.87058824, 0.92941176, 0.9372549 , 0.94901961,\n",
       "        0.96470588, 0.95294118, 0.95686275, 0.86666667, 0.8627451 ,\n",
       "        0.75686275, 0.74901961, 0.70196078, 0.71372549, 0.71372549,\n",
       "        0.70980392, 0.69019608, 0.65098039, 0.65882353, 0.38823529,\n",
       "        0.22745098, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n",
       "        0.28235294, 0.16078431, 0.1372549 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cb6c8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], x_train.shape[2], 1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], x_test.shape[2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93d8181f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a68927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', \n",
    "               input_shape=(28, 28, 1)),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "        BatchNormalization(),        \n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(256, kernel_size=(3, 3), activation='relu'),\n",
    "        BatchNormalization(),    \n",
    "        MaxPooling2D(pool_size=(2, 2)),   \n",
    "        \n",
    "        Flatten(),\n",
    "        \n",
    "        Dense(1024, activation='relu'),\n",
    "        \n",
    "        Dense(512, activation='relu'),\n",
    "        \n",
    "        Dense(10, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40553b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f408234d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 13, 13, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 11, 11, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 5, 5, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,940,938\n",
      "Trainable params: 1,939,146\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69445772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 353s 222ms/step - loss: 0.5598 - accuracy: 0.8028 - val_loss: 0.3619 - val_accuracy: 0.8720\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 332s 221ms/step - loss: 0.2815 - accuracy: 0.8964 - val_loss: 0.2951 - val_accuracy: 0.8906\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 332s 222ms/step - loss: 0.2337 - accuracy: 0.9145 - val_loss: 0.2490 - val_accuracy: 0.9118\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 334s 223ms/step - loss: 0.2006 - accuracy: 0.9257 - val_loss: 0.2419 - val_accuracy: 0.9136\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 333s 222ms/step - loss: 0.1727 - accuracy: 0.9364 - val_loss: 0.4247 - val_accuracy: 0.8627\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 333s 222ms/step - loss: 0.1538 - accuracy: 0.9439 - val_loss: 0.2231 - val_accuracy: 0.9195\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 333s 222ms/step - loss: 0.1265 - accuracy: 0.9532 - val_loss: 0.2573 - val_accuracy: 0.9212\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 332s 221ms/step - loss: 0.1118 - accuracy: 0.9597 - val_loss: 0.2425 - val_accuracy: 0.9282\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 330s 220ms/step - loss: 0.0915 - accuracy: 0.9666 - val_loss: 0.2862 - val_accuracy: 0.9290\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 330s 220ms/step - loss: 0.0778 - accuracy: 0.9715 - val_loss: 0.2654 - val_accuracy: 0.9262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f52776f5a50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model.fit(x_train, y_train_one_hot, epochs=10, verbose=1, batch_size = 32, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b3ba41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 14s 44ms/step - loss: 0.2967 - accuracy: 0.9195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9194999933242798"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "model.evaluate(x_test, y_test_one_hot)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bd5eb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5c13b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    " \n",
    "# load and prepare the image\n",
    "def load_image(filename):\n",
    "    # load the image\n",
    "    img = load_img(filename, grayscale=True, target_size=(28, 28))\n",
    "    # convert to array\n",
    "    img = img_to_array(img)\n",
    "    # reshape into a single sample with 1 channel\n",
    "    img = img.reshape(1, 28, 28, 1)\n",
    "    # prepare pixel data\n",
    "    img = img.astype('float32')\n",
    "    img = img / 255.0\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "627ee672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an image and predict the class\n",
    "def run_example():\n",
    "    # load the image\n",
    "    img = load_image('sample_test.png')\n",
    "    # load model\n",
    "    model = load_model('final_model.h5')\n",
    "    # predict the class\n",
    "    result = model.predict_classes(img)\n",
    "    \n",
    "\n",
    "    \n",
    "    return int(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a0d51d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = run_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78ac6976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pullover\n"
     ]
    }
   ],
   "source": [
    "if final == 0:\n",
    "        print(\"T-shirt/top\")\n",
    "elif final == 1:\n",
    "        print(\"Trouser\")\n",
    "elif final == 2:\n",
    "        print(\"Pullover\")\n",
    "elif final == 3:\n",
    "        print(\"Dress\")\n",
    "elif final == 4:\n",
    "        print(\"Coat\")\n",
    "elif final == 5:\n",
    "        print(\"Sandal\")\n",
    "elif final == 6:\n",
    "        print(\"Shirt\")\n",
    "elif final == 7:\n",
    "        print(\"Sneaker\")\n",
    "elif final == 8:\n",
    "        print(\"Bag\")\n",
    "elif final == 9:\n",
    "        print(\"Ankle Boot\")\n",
    "else:\n",
    "    print(\"No Categorized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c94e04f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-7ecdc8fb90d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtop_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop_3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" ({:.3})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop_3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "classes = np.array(train.columns[2:])\n",
    "proba = model.predict(img)\n",
    "top_3 = np.argsort(proba[0])[:-4:-1]\n",
    "for i in range(3):\n",
    "    print(\"{}\".format(classes[top_3[i]])+\" ({:.3})\".format(proba[0][top_3[i]]))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f8c125f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f52541e8290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[6.73429932e-12 1.18516069e-16 9.99999046e-01 1.02423715e-14\n",
      "  5.32306244e-09 4.72536134e-21 9.66902007e-07 4.99346586e-23\n",
      "  8.43459196e-17 2.55760164e-24]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img = load_image('sample_test.png')\n",
    "model = load_model('final_model.h5')\n",
    "result = model.predict(img)\n",
    "    \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4a4ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  true_label, img = true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  true_label = true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(10))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cda957",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  test_labels)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m69"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
